{
  "hash": "bbea65e10309e6f3f3c34baf63791fc3",
  "result": {
    "markdown": "---\ntitle: 'Blog 4 : Classification '\nauthor: Sandhya Vinukonda\ndate: '2023-12-06'\ncategories:\n  - Machine Learning\n  - Supervised Learning\n---\n\nClassification : The primary objective in supervised learning is to teach the model to predict the correct label or outcome for a given input. The model learns patterns and relationships in the training data, associating specific features with their corresponding labels.The training process involves exposing the model to the labeled training data, allowing it to adjust its internal parameters to make accurate predictions. Once trained, the model is then tested on new, unseen data (test data) to evaluate its generalization capabilities.The effectiveness of the supervised learning method is assessed by measuring its accuracy on the test data. Accuracy is calculated by comparing the model's predictions with the actual labels in the test set. This provides insights into how well the model performs on previously unseen examples.\n\n![](Supervised_Learning.png)\n\nIn supervised learning, where we already know the correct answers, there are two main flavors: classification and regression. The key factor in deciding which one to use is the nature of the label data. If your label data consists of continuous values, then it's a regression task. Take predicting house prices as an example – here, the goal is to estimate a continuous value based on features like square footage, location, and the number of bedrooms.On the flip side, if your task involves predicting categorical outcomes, like whether a student will be accepted into a specific university or not, then it's a classification problem. In this scenario, the label data has distinct categories (admitted or not admitted), making it suitable for a classification approach.So, whether you're dealing with predicting prices or university admissions, understanding if your label data is continuous or categorical guides you in choosing between regression and classification for your supervised learning journey.\n\n\nEager Learners:\nEager learners proactively build a model from a training dataset before making predictions.\nThey invest more time during the training process to generalize better by learning the weights and relationships within the data.\nOnce the model is trained, making predictions is relatively quicker.\nExamples:\nLogistic Regression: A widely-used algorithm for binary and multiclass classification. It models the probability of a certain class.\nSupport Vector Machine (SVM): Efficiently classifies data points by finding the optimal hyperplane that separates different classes.\nDecision Trees: Tree-like models that make decisions based on features at each node, suitable for classification and regression.\nArtificial Neural Networks (ANN): Complex models inspired by the human brain, composed of interconnected nodes that process information in layers.\n\n\nLazy Learners (Instance-Based Learners):\nCharacteristics:\n\nLazy learners don't construct a model immediately; they memorize the training data.\nDuring prediction, they dynamically search for the nearest neighbor from the entire training dataset.\nThis approach can be slower during prediction but adapts well to changes in the dataset.\nExamples:\n\nK-Nearest Neighbor (KNN): Classifies data points based on the majority class of their k-nearest neighbors.\nCase-Based Reasoning: Makes predictions based on past cases, comparing the current problem to previously solved ones.\nUnderstanding these distinctions helps in choosing the right algorithm based on the characteristics of the dataset and the specific requirements of the problem at hand. Eager and lazy learners offer different trade-offs in terms of training time, prediction speed, and adaptability to changes in the dataset.\n\n![](Classifcation_Types.png)\n\nTypes of Classifications : \n1. Binary : 0/1, spam and not spam, yes and no, negative and positive.\nExample : (long) \n2. Multi-class classification \nExample (one-vs-rest and one-vs-one)\n3. Multi-label classification \n4. Imbalanced classification \n\nLet’s get to coding! \n\n\nClassification takes place when the target variable is discrete. \nWhen a target variable isn't discrete, then regression takes place for the continuous varible. \n\nTypes of classification in ML : \n\nLet’s Start Coding \n\n![](LR_StepsOfCode.png)\n\nLet's look at a Machine Learning code example that shows binary classification of Blood Transfusion Service Centre. \n\nBefore we start coding let’s download the data and understand it. \nGo to link : https://archive.ics.uci.edu/dataset/176/blood+transfusion+service+center and click on download. \nAbout Data : This study focuses on the critical role of blood transfusions in saving lives, addressing the challenges of maintaining an adequate blood supply for medical needs. The research employs the RFMTC marketing model, a modified version of RFM, using the donor database of the Blood Transfusion Service Center in Hsin-Chu City, Taiwan. The study randomly selects 748 donors and gathers data on Recency, Frequency, Monetary contribution, Time, and a binary variable indicating blood donation in March 2007. This dataset forms the basis for \nbuilding an RFMTC model to enhance understanding and prediction in blood donation patterns.\n\nLet’s start coding : \n1. Import Libraries \n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import cross_val_score,  cross_val_predict\n```\n:::\n\n\n2. Read data and clean it \n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndata = pd.read_csv(r\"transfusion.csv\")\n# To rename the columns so that it is easier to call it \ndata=data.rename(columns={\"whether he/she donated blood in March 2007\":\"Present\"})\ndata=data.rename(columns={\"Recency (months)\":\"Recent\"})\ndata=data.rename(columns={\"Frequency (times)\":\"Frequency\"})\ndata=data.rename(columns={\"Monetary (c.c. blood)\":\"AmountOfBlood\"})\ndata=data.rename(columns={\"Time (months)\":\"Months\"})\n```\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ndata.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 748 entries, 0 to 747\nData columns (total 5 columns):\n #   Column         Non-Null Count  Dtype\n---  ------         --------------  -----\n 0   Recent         748 non-null    int64\n 1   Frequency      748 non-null    int64\n 2   AmountOfBlood  748 non-null    int64\n 3   Months         748 non-null    int64\n 4   Present        748 non-null    int64\ndtypes: int64(5)\nmemory usage: 29.3 KB\n```\n:::\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ndata.describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Recent</th>\n      <th>Frequency</th>\n      <th>AmountOfBlood</th>\n      <th>Months</th>\n      <th>Present</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>748.000000</td>\n      <td>748.000000</td>\n      <td>748.000000</td>\n      <td>748.000000</td>\n      <td>748.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>9.506684</td>\n      <td>5.514706</td>\n      <td>1378.676471</td>\n      <td>34.282086</td>\n      <td>0.237968</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>8.095396</td>\n      <td>5.839307</td>\n      <td>1459.826781</td>\n      <td>24.376714</td>\n      <td>0.426124</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>250.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.750000</td>\n      <td>2.000000</td>\n      <td>500.000000</td>\n      <td>16.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>7.000000</td>\n      <td>4.000000</td>\n      <td>1000.000000</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>14.000000</td>\n      <td>7.000000</td>\n      <td>1750.000000</td>\n      <td>50.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>74.000000</td>\n      <td>50.000000</td>\n      <td>12500.000000</td>\n      <td>98.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n3. Visualization of the data \n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nsns.heatmap(data.corr(),cmap=\"YlGnBu\")\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n<Axes: >\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-6-output-2.png){width=636 height=508}\n:::\n:::\n\n\n4. Splitting data into train and test\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n#To define a variable 'features' that has all the columns except the boolean column 'Present'\nfeatures=data.drop(\"Present\", axis=1)\n#To define a variable 'target' that has the boolean column 'Present'\ntarget = data[\"Present\"]\n\nX_train,X_test,Y_train,Y_test = train_test_split(features,target,test_size=0.3,random_state=101)\n```\n:::\n\n\n5. Model : Logistic Regression\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n#Using variable modelLR for logistic Regression\nmodelLR = LogisticRegression(solver='lbfgs')\n#To fit this data of training set of X and Y to the model\nmodelLR.fit(X_train, Y_train)\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```{=html}\n<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>\n```\n:::\n:::\n\n\n6. Evaluate the model \n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\n# modelLR = LogisticRegression()\npredLR = modelLR.predict(X_test)\n\n# Accuracy\nacc = accuracy_score(Y_test, predLR)\nprint(\"Accuracy = {:.2f}\".format(acc))\n\n# Precision\nprecision = precision_score(Y_test, predLR)\nprint(\"Precision = {:.2f}\".format(precision))\n\n# Recall\nrecall = recall_score(Y_test, predLR)\nprint(\"Recall = {:.2f}\".format(recall))\n\n# F1-score\nf1 = f1_score(Y_test, predLR)\nprint(\"F1 Score = {:.2f}\".format(f1))\n\n# Cross-validation\ny_pred_cv = cross_val_predict(modelLR, features, target, cv=10)\n\n# Cross-validation Accuracy\nresult_LR = cross_val_score(modelLR, features, target, cv=10, scoring=\"accuracy\")\nprint(\"Cross val Score = {:.2f}\".format(result_LR.mean()))\n\n# Cross-validation Precision\nprecision_cv = precision_score(target, y_pred_cv)\nprint(\"Cross val Precision = {:.2f}\".format(precision_cv))\n\n# Cross-validation Recall\nrecall_cv = recall_score(target, y_pred_cv)\nprint(\"Cross val Recall = {:.2f}\".format(recall_cv))\n\n# Cross-validation F1-score\nf1_cv = f1_score(target, y_pred_cv)\nprint(\"Cross val F1 Score = {:.2f}\".format(f1_cv))\n\n# Confusion Matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(confusion_matrix(target, y_pred_cv), cmap=\"summer\", annot=True, fmt=\"3.0f\")\nplt.title(\"Confusion Matrix (Cross-validated)\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy = 0.75\nPrecision = 0.50\nRecall = 0.05\nF1 Score = 0.10\nCross val Score = 0.77\nCross val Precision = 0.55\nCross val Recall = 0.16\nCross val F1 Score = 0.24\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-9-output-2.png){width=604 height=505}\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}