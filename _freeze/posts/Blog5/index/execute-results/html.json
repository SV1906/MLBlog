{
  "hash": "9e08c8d06437553752d45f129b40e752",
  "result": {
    "markdown": "---\ntitle: 'Blog 5 : Anomaly/Outliers Detection'\nauthor: Sandhya Vinukonda\ndate: '2023-12-06'\ncategories:\n  - Machine Learning\n  - Anomaly Detection\n  - Outlier Analysis\n---\n\nIn the intricate landscape of data analysis, outliers emerge as the unconventional elements that refuse to conform. These peculiar data points, standing out from the crowd, can introduce significant distortions to the overall dataset. Whether stemming from errors, inconsistencies, or simply unique observations, managing outliers becomes a pivotal step in the process of data cleaning and preprocessing. This careful curation ensures that our analytical endeavors are built upon trustworthy and representative data.\n\nThe Significance of Outlier Detection:\n\nThink of outlier detection as playing detective with our dataset. During the crucial phases of cleaning and preprocessing, where we address missing values and pinpoint outliers, it's imperative to contextualize our actions. The decision to remove outliers should be influenced by the specific use case, as blindly discarding data points may not always align with the broader objectives. The ultimate aim is to bolster our model's performance when faced with new or unseen data.\n![](Outliers.png)\n\nStrategies for Outlier Detection:\n\n![](Outliers_Detection.png)\n \n\n1. Using Standard Deviation:\nAn approach grounded in setting limits based on standard deviations.\nLower Limit: μ - 3σ, Upper Limit: μ + 3σ.\nAny data point beyond this range is flagged as an outlier.\nThis method relies on the assumption that 99.7% of data falls within three standard deviations.\n2. Using Z-score:\nStandard deviation is a metric of variance, i.e., how much the individual data points are spread out from the mean. In statistics, if a data distribution is approximately normal, then about 68% of the data values lie within one standard deviation of the mean and about 95% are within two standard deviations, and about 99.7% lie within three standard deviations.\nThe Z-score is the signed number of standard deviations by which the value of an observation or data point is above the mean value of what is being observed or measured.\nThe intuition behind the Z-score is to describe any data point by finding its relationship with the Standard Deviation and Mean of the group of data points. Z-score is finding the distribution of data where mean is 0 and standard deviation is 1, i.e., normal distribution.\nYou must be wondering how this helps in identifying the outliers. While calculating the Z-score, we re-scale and center the data and look for data points that are too far from zero. These data points, which are way too far from zero, will be treated as the outliers. In most cases, a threshold of 3 or -3 is used, i.e., if the Z-score value is greater than or less than 3 or -3, respectively, that data point will be identified as an outlier.\nThis technique assumes a Gaussian distribution of the data. The outliers are the data points that are in the tails of the distribution and therefore far from the mean. How far depends on a set threshold for the normalized data points calculated with the formula: \n\nAn outlier is then a normalized data point that has an absolute value greater than z(thr). That is |z(score)| > z(thr). Commonly used Z(thr) values are 2.5, 3.0, and 3.5. Here we will be using 3.0. For example, I'll take up the Medical Cost Personal Datasets for explaining the Z-Score method.This technique assumes a Gaussian distribution of the data.\n\n3. Using IQR (Interquartile Range):\n\nThe concept of the Interquartile Range (IQR) is used to build the boxplot graphs. IQR is a concept in statistics that is used to measure the statistical dispersion and data variability by dividing the dataset into quartiles.In simple words, any dataset or any set of observations is divided into four defined intervals based upon the values of the data and how they compare to the entire dataset. A quartile is what divides the data into three points and four intervals.It is the difference between the third quartile and the first quartile (IQR = Q3 - Q1). Outliers in this case are defined as the observations that are below (Q1−1.5×IQR) or above (Q3+1.5×IQR) or boxplot lower whisker or above boxplot upper whisker. It can be visually represented by the box plot.\n\nFocused on the central 50% of data.\nOutliers are identified outside the range[q25−1.5×IQR,q75+1.5×IQR]\n\n![](Outliers_Boxplot.png)\nhttps://www.kdnuggets.com/2019/11/understanding-boxplots.html\n\n\n\n4. Using Percentile:Leveraging percentiles to isolate outliers outside the interquartile range.Outliers are discarded if they stray beyond the confines of [q25−1.5×IQR,q75+1.5×IQR].\nIn the intricate dance of data analysis, the ability to detect and navigate outliers is akin to mastering a subtle art. Employing techniques such as standard deviation, z-score, IQR, and percentiles empowers us to pinpoint and manage anomalies with finesse. The choice of method is nuanced, guided by the unique characteristics of the dataset and the specific demands of the analysis. By embracing the challenge of outlier detection, we fortify our data's integrity, ensuring it stands resilient and poised for insightful revelations.\nMore Content:\nOutliers can have many causes, such as:\nMeasurement or input error.\nData corruption.\nTrue outlier observation.\nThere is no precise way to define and identify outliers in general because of the specifics of each dataset. Instead, you, or a domain expert, must interpret the raw observations and decide whether a value is an outlier or not.\nNevertheless, we can use statistical methods to identify observations that appear to be rare or unlikely given the available data. This does not mean that the values identified are outliers and should be removed. A good tip is to consider plotting the identified outlier values, perhaps in the context of non-outlier values to see if there are any systematic relationships or patterns to the outliers.\n\nTypes of Outliers:\n\nOutliers can be of two types:\n\n1. Univariate\n2. Multivariate.\n\nUnivariate outliers can be found when we look at the distribution of a single variable. Multivariate outliers are outliers in an n-dimensional space. In order to find them, you have to look at distributions in multi-dimensions.\nLet us understand this with an example. Let's say we are understanding the relationship between height and weight. Below, we have univariate and bivariate distribution for Height and Weight. Take a look at the box plot. We do not have any outliers (above and below 1.5 * IQR, a common method). Now look at the scatter plot. Here, we have two values below and one above the average in a specific segment of weight and height.\n\nImpact of Outliers on a Dataset:\nOutliers can drastically change the results of data analysis and statistical modeling. There are numerous unfavorable impacts of outliers in the dataset:\nIt increases the error variance and reduces the power of statistical tests.\nIf the outliers are non-randomly distributed, they can decrease normality.\nThey can bias or influence estimates that may be of substantive interest.\nThey can also impact the basic assumption of Regression, ANOVA, and other statistical model assumptions.\nTo understand the impact deeply, let’s take an example to check what happens to a dataset with and without outliers in the dataset.\n\n\nCode : \nFor percentile \n1. Import all the libraries \n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.datasets import load_wine\nimport scipy.stats\n```\n:::\n\n\n2. Load and clean the dataset \n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# Load the Wine dataset\nwine = load_wine()\ndata = wine.data\nfeature_names = wine.feature_names\n```\n:::\n\n\n3. Finding the percentile\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n# Function for outlier detection using Percentile\ndef detect_outliers_percentile(data, feature_index, lower_percentile=5, upper_percentile=95):\n    feature_data = data[:, feature_index]\n    lower_bound = np.percentile(feature_data, lower_percentile)\n    upper_bound = np.percentile(feature_data, upper_percentile)\n    outliers = data[(feature_data < lower_bound) | (feature_data > upper_bound)]\n    return outliers\n# Example usage:\n\n# Outlier detection using Percentile\npercentile_outliers = detect_outliers_percentile(data, feature_index=0)\n```\n:::\n\n\n4. Visualization\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n# Function for plotting the data and outliers\ndef plot_data_with_outliers(data, outliers, feature_name, method_name, title):\n    plt.figure(figsize=(10, 6))\n    sns.scatterplot(x=data[:, 0], y=data[:, 1], label='Inliers', color='green', alpha=0.7)\n    sns.scatterplot(x=outliers[:, 0], y=outliers[:, 1], label='Outliers', color='purple', marker='X', s=100)\n    plt.title(f'{title} ({method_name})', fontsize=16)\n    plt.xlabel(feature_name, fontsize=14)\n    plt.ylabel('Target', fontsize=14)\n    plt.xticks(fontsize=12)\n    plt.yticks(fontsize=12)\n    plt.legend(fontsize=12)\n    plt.show()\n\n\n# Plotting the original data and outliers detected using Percentile\nplot_data_with_outliers(data, percentile_outliers, feature_name=feature_names[0], method_name='Percentile', title='Outliers Detected')\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-1.png){width=821 height=536}\n:::\n:::\n\n\nFor Standard Deviation\nDownload the dataset from : https://www.kaggle.com/datasets/spscientist/students-performance-in-exams\n\n1. Import libraries \n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nimport pandas as pd\n```\n:::\n\n\n2. Read the dataset \n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ndf_2 = pd.read_csv(\"StudentsPerformance.csv\")\ndf_2.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>race/ethnicity</th>\n      <th>parental level of education</th>\n      <th>lunch</th>\n      <th>test preparation course</th>\n      <th>math score</th>\n      <th>reading score</th>\n      <th>writing score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>female</td>\n      <td>group B</td>\n      <td>bachelor's degree</td>\n      <td>standard</td>\n      <td>none</td>\n      <td>72</td>\n      <td>72</td>\n      <td>74</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>female</td>\n      <td>group C</td>\n      <td>some college</td>\n      <td>standard</td>\n      <td>completed</td>\n      <td>69</td>\n      <td>90</td>\n      <td>88</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>female</td>\n      <td>group B</td>\n      <td>master's degree</td>\n      <td>standard</td>\n      <td>none</td>\n      <td>90</td>\n      <td>95</td>\n      <td>93</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>male</td>\n      <td>group A</td>\n      <td>associate's degree</td>\n      <td>free/reduced</td>\n      <td>none</td>\n      <td>47</td>\n      <td>57</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>male</td>\n      <td>group C</td>\n      <td>some college</td>\n      <td>standard</td>\n      <td>none</td>\n      <td>76</td>\n      <td>78</td>\n      <td>75</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n3. Standard deviation \n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\ndef out_std(df, column):\n    global lower,upper\n    # calculate the mean and standard deviation of the data frame\n    data_mean, data_std = df[column].mean(), df[column].std()\n    # calculate the cutoff value\n    cut_off = data_std * 3\n    # calculate the lower and upper bound value\n    lower, upper = data_mean - cut_off, data_mean + cut_off\n    print('The lower bound value is', lower)\n    print('The upper bound value is', upper)\n    # Calculate the number of records below and above lower and above bound value respectively\n    df1 = df[df[column] > upper]\n    df2 = df[df[column] < lower]\n    return print('Total number of outliers are', df1.shape[0]+ df2.shape[0])\n```\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nout_std(df_2,'writing score')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe lower bound value is 22.46702896739105\nThe upper bound value is 113.64097103260895\nTotal number of outliers are 4\n```\n:::\n:::\n\n\n4. Visualization \n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nplt.figure(figsize = (10,5))\nsns.distplot(df_2['writing score'])\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\gayat\\AppData\\Local\\Temp\\ipykernel_18120\\1994446283.py:2: UserWarning:\n\n\n\n`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n\nPlease adapt your code to use either `displot` (a figure-level function with\nsimilar flexibility) or `histplot` (an axes-level function for histograms).\n\nFor a guide to updating your code to use the new functions, please see\nhttps://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n\n\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\n<Axes: xlabel='writing score', ylabel='Density'>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-10-output-3.png){width=829 height=429}\n:::\n:::\n\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nplt.figure(figsize = (10,5))\nsns.distplot(df_2['writing score'], kde=False)\nplt.axvspan(xmin = lower,xmax= df_2['writing score'].min(),alpha=0.2, color='red')\nplt.axvspan(xmin = upper,xmax= df_2['writing score'].max(),alpha=0.2, color='red')\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\gayat\\AppData\\Local\\Temp\\ipykernel_18120\\3774281472.py:2: UserWarning:\n\n\n\n`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n\nPlease adapt your code to use either `displot` (a figure-level function with\nsimilar flexibility) or `histplot` (an axes-level function for histograms).\n\nFor a guide to updating your code to use the new functions, please see\nhttps://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n\n\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\n<matplotlib.patches.Polygon at 0x2827dfb4790>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-11-output-3.png){width=798 height=429}\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}