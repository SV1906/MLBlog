[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning Blogs",
    "section": "",
    "text": "Blog 1 : Probability theory and random variables\n\n\n\n\n\n\n\nProbability\n\n\nStatistics\n\n\n\n\n\n\n\n\n\n\n\nDec 6, 2023\n\n\nSandhya Vinukonda\n\n\n\n\n\n\n  \n\n\n\n\nBlog 2 : Clustering\n\n\n\n\n\n\n\nMachine Learning\n\n\nUnsupervised Learning\n\n\n\n\n\n\n\n\n\n\n\nDec 6, 2023\n\n\nSandhya Vinukonda\n\n\n\n\n\n\n  \n\n\n\n\nBlog 3 : Linear and nonlinear regression\n\n\n\n\n\n\n\nMachine Learning\n\n\nRegression Analysis\n\n\n\n\n\n\n\n\n\n\n\nDec 6, 2023\n\n\nSandhya Vinukonda\n\n\n\n\n\n\n  \n\n\n\n\nBlog 4 : Classification\n\n\n\n\n\n\n\nMachine Learning\n\n\nSupervised Learning\n\n\n\n\n\n\n\n\n\n\n\nDec 6, 2023\n\n\nSandhya Vinukonda\n\n\n\n\n\n\n  \n\n\n\n\nBlog 5 : Anomaly/Outliers Detection\n\n\n\n\n\n\n\nMachine Learning\n\n\nAnomaly Detection\n\n\nOutlier Analysis\n\n\n\n\n\n\n\n\n\n\n\nDec 6, 2023\n\n\nSandhya Vinukonda\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Blog4/index.html",
    "href": "posts/Blog4/index.html",
    "title": "Blog 4 : Classification",
    "section": "",
    "text": "Classification : The primary objective in supervised learning is to teach the model to predict the correct label or outcome for a given input. The model learns patterns and relationships in the training data, associating specific features with their corresponding labels.The training process involves exposing the model to the labeled training data, allowing it to adjust its internal parameters to make accurate predictions. Once trained, the model is then tested on new, unseen data (test data) to evaluate its generalization capabilities.The effectiveness of the supervised learning method is assessed by measuring its accuracy on the test data. Accuracy is calculated by comparing the model’s predictions with the actual labels in the test set. This provides insights into how well the model performs on previously unseen examples.\n\nIn supervised learning, where we already know the correct answers, there are two main flavors: classification and regression. The key factor in deciding which one to use is the nature of the label data. If your label data consists of continuous values, then it’s a regression task. Take predicting house prices as an example – here, the goal is to estimate a continuous value based on features like square footage, location, and the number of bedrooms.On the flip side, if your task involves predicting categorical outcomes, like whether a student will be accepted into a specific university or not, then it’s a classification problem. In this scenario, the label data has distinct categories (admitted or not admitted), making it suitable for a classification approach.So, whether you’re dealing with predicting prices or university admissions, understanding if your label data is continuous or categorical guides you in choosing between regression and classification for your supervised learning journey.\nEager Learners: Eager learners proactively build a model from a training dataset before making predictions. They invest more time during the training process to generalize better by learning the weights and relationships within the data. Once the model is trained, making predictions is relatively quicker. Examples: Logistic Regression: A widely-used algorithm for binary and multiclass classification. It models the probability of a certain class. Support Vector Machine (SVM): Efficiently classifies data points by finding the optimal hyperplane that separates different classes. Decision Trees: Tree-like models that make decisions based on features at each node, suitable for classification and regression. Artificial Neural Networks (ANN): Complex models inspired by the human brain, composed of interconnected nodes that process information in layers.\nLazy Learners (Instance-Based Learners): Characteristics:\nLazy learners don’t construct a model immediately; they memorize the training data. During prediction, they dynamically search for the nearest neighbor from the entire training dataset. This approach can be slower during prediction but adapts well to changes in the dataset. Examples:\nK-Nearest Neighbor (KNN): Classifies data points based on the majority class of their k-nearest neighbors. Case-Based Reasoning: Makes predictions based on past cases, comparing the current problem to previously solved ones. Understanding these distinctions helps in choosing the right algorithm based on the characteristics of the dataset and the specific requirements of the problem at hand. Eager and lazy learners offer different trade-offs in terms of training time, prediction speed, and adaptability to changes in the dataset.\n\nTypes of Classifications : 1. Binary : 0/1, spam and not spam, yes and no, negative and positive. Example : (long) 2. Multi-class classification Example (one-vs-rest and one-vs-one) 3. Multi-label classification 4. Imbalanced classification\nLet’s get to coding!\nClassification takes place when the target variable is discrete. When a target variable isn’t discrete, then regression takes place for the continuous varible.\nTypes of classification in ML :\nLet’s Start Coding\n\nLet’s look at a Machine Learning code example that shows binary classification of Blood Transfusion Service Centre.\nBefore we start coding let’s download the data and understand it. Go to link : https://archive.ics.uci.edu/dataset/176/blood+transfusion+service+center and click on download. About Data : This study focuses on the critical role of blood transfusions in saving lives, addressing the challenges of maintaining an adequate blood supply for medical needs. The research employs the RFMTC marketing model, a modified version of RFM, using the donor database of the Blood Transfusion Service Center in Hsin-Chu City, Taiwan. The study randomly selects 748 donors and gathers data on Recency, Frequency, Monetary contribution, Time, and a binary variable indicating blood donation in March 2007. This dataset forms the basis for building an RFMTC model to enhance understanding and prediction in blood donation patterns.\nLet’s start coding : 1. Import Libraries\n\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import cross_val_score,  cross_val_predict\n\n\nRead data and clean it\n\n\ndata = pd.read_csv(r\"transfusion.csv\")\n# To rename the columns so that it is easier to call it \ndata=data.rename(columns={\"whether he/she donated blood in March 2007\":\"Present\"})\ndata=data.rename(columns={\"Recency (months)\":\"Recent\"})\ndata=data.rename(columns={\"Frequency (times)\":\"Frequency\"})\ndata=data.rename(columns={\"Monetary (c.c. blood)\":\"AmountOfBlood\"})\ndata=data.rename(columns={\"Time (months)\":\"Months\"})\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 748 entries, 0 to 747\nData columns (total 5 columns):\n #   Column         Non-Null Count  Dtype\n---  ------         --------------  -----\n 0   Recent         748 non-null    int64\n 1   Frequency      748 non-null    int64\n 2   AmountOfBlood  748 non-null    int64\n 3   Months         748 non-null    int64\n 4   Present        748 non-null    int64\ndtypes: int64(5)\nmemory usage: 29.3 KB\n\n\n\ndata.describe()\n\n\n\n\n\n\n\n\nRecent\nFrequency\nAmountOfBlood\nMonths\nPresent\n\n\n\n\ncount\n748.000000\n748.000000\n748.000000\n748.000000\n748.000000\n\n\nmean\n9.506684\n5.514706\n1378.676471\n34.282086\n0.237968\n\n\nstd\n8.095396\n5.839307\n1459.826781\n24.376714\n0.426124\n\n\nmin\n0.000000\n1.000000\n250.000000\n2.000000\n0.000000\n\n\n25%\n2.750000\n2.000000\n500.000000\n16.000000\n0.000000\n\n\n50%\n7.000000\n4.000000\n1000.000000\n28.000000\n0.000000\n\n\n75%\n14.000000\n7.000000\n1750.000000\n50.000000\n0.000000\n\n\nmax\n74.000000\n50.000000\n12500.000000\n98.000000\n1.000000\n\n\n\n\n\n\n\n\nVisualization of the data\n\n\nsns.heatmap(data.corr(),cmap=\"YlGnBu\")\n\n&lt;Axes: &gt;\n\n\n\n\n\n\nSplitting data into train and test\n\n\n#To define a variable 'features' that has all the columns except the boolean column 'Present'\nfeatures=data.drop(\"Present\", axis=1)\n#To define a variable 'target' that has the boolean column 'Present'\ntarget = data[\"Present\"]\n\nX_train,X_test,Y_train,Y_test = train_test_split(features,target,test_size=0.3,random_state=101)\n\n\nModel : Logistic Regression\n\n\n#Using variable modelLR for logistic Regression\nmodelLR = LogisticRegression(solver='lbfgs')\n#To fit this data of training set of X and Y to the model\nmodelLR.fit(X_train, Y_train)\n\nLogisticRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegressionLogisticRegression()\n\n\n\nEvaluate the model\n\n\n# modelLR = LogisticRegression()\npredLR = modelLR.predict(X_test)\n\n# Accuracy\nacc = accuracy_score(Y_test, predLR)\nprint(\"Accuracy = {:.2f}\".format(acc))\n\n# Precision\nprecision = precision_score(Y_test, predLR)\nprint(\"Precision = {:.2f}\".format(precision))\n\n# Recall\nrecall = recall_score(Y_test, predLR)\nprint(\"Recall = {:.2f}\".format(recall))\n\n# F1-score\nf1 = f1_score(Y_test, predLR)\nprint(\"F1 Score = {:.2f}\".format(f1))\n\n# Cross-validation\ny_pred_cv = cross_val_predict(modelLR, features, target, cv=10)\n\n# Cross-validation Accuracy\nresult_LR = cross_val_score(modelLR, features, target, cv=10, scoring=\"accuracy\")\nprint(\"Cross val Score = {:.2f}\".format(result_LR.mean()))\n\n# Cross-validation Precision\nprecision_cv = precision_score(target, y_pred_cv)\nprint(\"Cross val Precision = {:.2f}\".format(precision_cv))\n\n# Cross-validation Recall\nrecall_cv = recall_score(target, y_pred_cv)\nprint(\"Cross val Recall = {:.2f}\".format(recall_cv))\n\n# Cross-validation F1-score\nf1_cv = f1_score(target, y_pred_cv)\nprint(\"Cross val F1 Score = {:.2f}\".format(f1_cv))\n\n# Confusion Matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(confusion_matrix(target, y_pred_cv), cmap=\"summer\", annot=True, fmt=\"3.0f\")\nplt.title(\"Confusion Matrix (Cross-validated)\")\nplt.show()\n\nAccuracy = 0.75\nPrecision = 0.50\nRecall = 0.05\nF1 Score = 0.10\nCross val Score = 0.77\nCross val Precision = 0.55\nCross val Recall = 0.16\nCross val F1 Score = 0.24"
  },
  {
    "objectID": "posts/Blog5/index.html",
    "href": "posts/Blog5/index.html",
    "title": "Blog 5 : Anomaly/Outliers Detection",
    "section": "",
    "text": "In the intricate landscape of data analysis, outliers emerge as the unconventional elements that refuse to conform. These peculiar data points, standing out from the crowd, can introduce significant distortions to the overall dataset. Whether stemming from errors, inconsistencies, or simply unique observations, managing outliers becomes a pivotal step in the process of data cleaning and preprocessing. This careful curation ensures that our analytical endeavors are built upon trustworthy and representative data.\nThe Significance of Outlier Detection:\nThink of outlier detection as playing detective with our dataset. During the crucial phases of cleaning and preprocessing, where we address missing values and pinpoint outliers, it’s imperative to contextualize our actions. The decision to remove outliers should be influenced by the specific use case, as blindly discarding data points may not always align with the broader objectives. The ultimate aim is to bolster our model’s performance when faced with new or unseen data. \nStrategies for Outlier Detection:\n\n\nUsing Standard Deviation: An approach grounded in setting limits based on standard deviations. Lower Limit: μ - 3σ, Upper Limit: μ + 3σ. Any data point beyond this range is flagged as an outlier. This method relies on the assumption that 99.7% of data falls within three standard deviations.\nUsing Z-score: Standard deviation is a metric of variance, i.e., how much the individual data points are spread out from the mean. In statistics, if a data distribution is approximately normal, then about 68% of the data values lie within one standard deviation of the mean and about 95% are within two standard deviations, and about 99.7% lie within three standard deviations. The Z-score is the signed number of standard deviations by which the value of an observation or data point is above the mean value of what is being observed or measured. The intuition behind the Z-score is to describe any data point by finding its relationship with the Standard Deviation and Mean of the group of data points. Z-score is finding the distribution of data where mean is 0 and standard deviation is 1, i.e., normal distribution. You must be wondering how this helps in identifying the outliers. While calculating the Z-score, we re-scale and center the data and look for data points that are too far from zero. These data points, which are way too far from zero, will be treated as the outliers. In most cases, a threshold of 3 or -3 is used, i.e., if the Z-score value is greater than or less than 3 or -3, respectively, that data point will be identified as an outlier. This technique assumes a Gaussian distribution of the data. The outliers are the data points that are in the tails of the distribution and therefore far from the mean. How far depends on a set threshold for the normalized data points calculated with the formula:\n\nAn outlier is then a normalized data point that has an absolute value greater than z(thr). That is |z(score)| &gt; z(thr). Commonly used Z(thr) values are 2.5, 3.0, and 3.5. Here we will be using 3.0. For example, I’ll take up the Medical Cost Personal Datasets for explaining the Z-Score method.This technique assumes a Gaussian distribution of the data.\n\nUsing IQR (Interquartile Range):\n\nThe concept of the Interquartile Range (IQR) is used to build the boxplot graphs. IQR is a concept in statistics that is used to measure the statistical dispersion and data variability by dividing the dataset into quartiles.In simple words, any dataset or any set of observations is divided into four defined intervals based upon the values of the data and how they compare to the entire dataset. A quartile is what divides the data into three points and four intervals.It is the difference between the third quartile and the first quartile (IQR = Q3 - Q1). Outliers in this case are defined as the observations that are below (Q1−1.5×IQR) or above (Q3+1.5×IQR) or boxplot lower whisker or above boxplot upper whisker. It can be visually represented by the box plot.\nFocused on the central 50% of data. Outliers are identified outside the range[q25−1.5×IQR,q75+1.5×IQR]\n https://www.kdnuggets.com/2019/11/understanding-boxplots.html\n\nUsing Percentile:Leveraging percentiles to isolate outliers outside the interquartile range.Outliers are discarded if they stray beyond the confines of [q25−1.5×IQR,q75+1.5×IQR]. In the intricate dance of data analysis, the ability to detect and navigate outliers is akin to mastering a subtle art. Employing techniques such as standard deviation, z-score, IQR, and percentiles empowers us to pinpoint and manage anomalies with finesse. The choice of method is nuanced, guided by the unique characteristics of the dataset and the specific demands of the analysis. By embracing the challenge of outlier detection, we fortify our data’s integrity, ensuring it stands resilient and poised for insightful revelations. More Content: Outliers can have many causes, such as: Measurement or input error. Data corruption. True outlier observation. There is no precise way to define and identify outliers in general because of the specifics of each dataset. Instead, you, or a domain expert, must interpret the raw observations and decide whether a value is an outlier or not. Nevertheless, we can use statistical methods to identify observations that appear to be rare or unlikely given the available data. This does not mean that the values identified are outliers and should be removed. A good tip is to consider plotting the identified outlier values, perhaps in the context of non-outlier values to see if there are any systematic relationships or patterns to the outliers.\n\nTypes of Outliers:\nOutliers can be of two types:\n\nUnivariate\nMultivariate.\n\nUnivariate outliers can be found when we look at the distribution of a single variable. Multivariate outliers are outliers in an n-dimensional space. In order to find them, you have to look at distributions in multi-dimensions. Let us understand this with an example. Let’s say we are understanding the relationship between height and weight. Below, we have univariate and bivariate distribution for Height and Weight. Take a look at the box plot. We do not have any outliers (above and below 1.5 * IQR, a common method). Now look at the scatter plot. Here, we have two values below and one above the average in a specific segment of weight and height.\nImpact of Outliers on a Dataset: Outliers can drastically change the results of data analysis and statistical modeling. There are numerous unfavorable impacts of outliers in the dataset: It increases the error variance and reduces the power of statistical tests. If the outliers are non-randomly distributed, they can decrease normality. They can bias or influence estimates that may be of substantive interest. They can also impact the basic assumption of Regression, ANOVA, and other statistical model assumptions. To understand the impact deeply, let’s take an example to check what happens to a dataset with and without outliers in the dataset.\nCode : For percentile 1. Import all the libraries\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.datasets import load_wine\nimport scipy.stats\n\n\nLoad and clean the dataset\n\n\n# Load the Wine dataset\nwine = load_wine()\ndata = wine.data\nfeature_names = wine.feature_names\n\n\nFinding the percentile\n\n\n# Function for outlier detection using Percentile\ndef detect_outliers_percentile(data, feature_index, lower_percentile=5, upper_percentile=95):\n    feature_data = data[:, feature_index]\n    lower_bound = np.percentile(feature_data, lower_percentile)\n    upper_bound = np.percentile(feature_data, upper_percentile)\n    outliers = data[(feature_data &lt; lower_bound) | (feature_data &gt; upper_bound)]\n    return outliers\n# Example usage:\n\n# Outlier detection using Percentile\npercentile_outliers = detect_outliers_percentile(data, feature_index=0)\n\n\nVisualization\n\n\n# Function for plotting the data and outliers\ndef plot_data_with_outliers(data, outliers, feature_name, method_name, title):\n    plt.figure(figsize=(10, 6))\n    sns.scatterplot(x=data[:, 0], y=data[:, 1], label='Inliers', color='green', alpha=0.7)\n    sns.scatterplot(x=outliers[:, 0], y=outliers[:, 1], label='Outliers', color='purple', marker='X', s=100)\n    plt.title(f'{title} ({method_name})', fontsize=16)\n    plt.xlabel(feature_name, fontsize=14)\n    plt.ylabel('Target', fontsize=14)\n    plt.xticks(fontsize=12)\n    plt.yticks(fontsize=12)\n    plt.legend(fontsize=12)\n    plt.show()\n\n\n# Plotting the original data and outliers detected using Percentile\nplot_data_with_outliers(data, percentile_outliers, feature_name=feature_names[0], method_name='Percentile', title='Outliers Detected')\n\n\n\n\nFor Standard Deviation Download the dataset from : https://www.kaggle.com/datasets/spscientist/students-performance-in-exams\n\nImport libraries\n\n\nimport pandas as pd\n\n\nRead the dataset\n\n\ndf_2 = pd.read_csv(\"StudentsPerformance.csv\")\ndf_2.head()\n\n\n\n\n\n\n\n\ngender\nrace/ethnicity\nparental level of education\nlunch\ntest preparation course\nmath score\nreading score\nwriting score\n\n\n\n\n0\nfemale\ngroup B\nbachelor's degree\nstandard\nnone\n72\n72\n74\n\n\n1\nfemale\ngroup C\nsome college\nstandard\ncompleted\n69\n90\n88\n\n\n2\nfemale\ngroup B\nmaster's degree\nstandard\nnone\n90\n95\n93\n\n\n3\nmale\ngroup A\nassociate's degree\nfree/reduced\nnone\n47\n57\n44\n\n\n4\nmale\ngroup C\nsome college\nstandard\nnone\n76\n78\n75\n\n\n\n\n\n\n\n\nStandard deviation\n\n\ndef out_std(df, column):\n    global lower,upper\n    # calculate the mean and standard deviation of the data frame\n    data_mean, data_std = df[column].mean(), df[column].std()\n    # calculate the cutoff value\n    cut_off = data_std * 3\n    # calculate the lower and upper bound value\n    lower, upper = data_mean - cut_off, data_mean + cut_off\n    print('The lower bound value is', lower)\n    print('The upper bound value is', upper)\n    # Calculate the number of records below and above lower and above bound value respectively\n    df1 = df[df[column] &gt; upper]\n    df2 = df[df[column] &lt; lower]\n    return print('Total number of outliers are', df1.shape[0]+ df2.shape[0])\n\n\nout_std(df_2,'writing score')\n\nThe lower bound value is 22.46702896739105\nThe upper bound value is 113.64097103260895\nTotal number of outliers are 4\n\n\n\nVisualization\n\n\nplt.figure(figsize = (10,5))\nsns.distplot(df_2['writing score'])\n\nC:\\Users\\gayat\\AppData\\Local\\Temp\\ipykernel_18120\\1994446283.py:2: UserWarning:\n\n\n\n`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n\nPlease adapt your code to use either `displot` (a figure-level function with\nsimilar flexibility) or `histplot` (an axes-level function for histograms).\n\nFor a guide to updating your code to use the new functions, please see\nhttps://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n\n\n\n\n&lt;Axes: xlabel='writing score', ylabel='Density'&gt;\n\n\n\n\n\n\nplt.figure(figsize = (10,5))\nsns.distplot(df_2['writing score'], kde=False)\nplt.axvspan(xmin = lower,xmax= df_2['writing score'].min(),alpha=0.2, color='red')\nplt.axvspan(xmin = upper,xmax= df_2['writing score'].max(),alpha=0.2, color='red')\n\nC:\\Users\\gayat\\AppData\\Local\\Temp\\ipykernel_18120\\3774281472.py:2: UserWarning:\n\n\n\n`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n\nPlease adapt your code to use either `displot` (a figure-level function with\nsimilar flexibility) or `histplot` (an axes-level function for histograms).\n\nFor a guide to updating your code to use the new functions, please see\nhttps://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n\n\n\n\n&lt;matplotlib.patches.Polygon at 0x2827dfb4790&gt;"
  }
]